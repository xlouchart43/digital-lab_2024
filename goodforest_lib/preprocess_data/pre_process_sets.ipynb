{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing set for training and testing\n",
    "\n",
    "This notebook enables you to preprocess the training and testing data in order to train a Deep-Learning model.\n",
    "\n",
    "This script requires a cube file with h5 format.\n",
    "\n",
    "The resulting output enables to define a train, validation and test set while keeping the same distribution of the classes, which is important for the less frequent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from goodforest_lib.config.constants import RANDOM_SEED\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/raw/BC/diverse/\"\n",
    "filename = \"cubes_4-sick-classes_diverse_IB_filtered.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6254, 25, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path+filename, 'r') as hf:\n",
    "    data = hf['cubes'][:]\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionnary to store keys, values where keys are the class labels and values are the cubes indices\n",
    "NB_CLASSES = 6\n",
    "classes = {i:dict() for i in range(NB_CLASSES)}\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    labels = data[i, -1]\n",
    "    unique_label, unique_label_count = np.unique(labels, return_counts=True)\n",
    "    for label, count in zip(unique_label, unique_label_count):\n",
    "        classes[label][i] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of cubes with only 0 and 1 classes: 63.16%\n"
     ]
    }
   ],
   "source": [
    "only_1_and_0_cubes = set(classes[0].keys()).union(classes[1].keys())\n",
    "for i in range(2, NB_CLASSES):\n",
    "    only_1_and_0_cubes = only_1_and_0_cubes - set(classes[i].keys())\n",
    "only_1_and_0_cubes = list(only_1_and_0_cubes)\n",
    "print(f\"Percentage of cubes with only 0 and 1 classes: {len(only_1_and_0_cubes)/data.shape[0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set, test_set = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cubes = set()\n",
    "custom_range = list(range(2, NB_CLASSES))\n",
    "\n",
    "np.random.shuffle(custom_range)\n",
    "\n",
    "proportion_per_set = [0.8, 0.1, 0.1]\n",
    "\n",
    "for class_label in custom_range:\n",
    "    cubes_indices = list(set(classes[class_label].keys()) - chosen_cubes)\n",
    "    chosen_cubes = chosen_cubes.union(set(cubes_indices))\n",
    "    if len(cubes_indices) < 3:\n",
    "        print(f\"Class {class_label} corresponding to {(class_label-4)//2} has {len(cubes_indices)} cubes\")\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(cubes_indices)\n",
    "    temp_train_set = set(cubes_indices[:int(len(cubes_indices)*proportion_per_set[0])])\n",
    "    temp_validation_set = cubes_indices[int(len(cubes_indices)*proportion_per_set[0]):int(len(cubes_indices)*(proportion_per_set[0]+proportion_per_set[1]))]\n",
    "    temp_test_set = cubes_indices[int(len(cubes_indices)*(proportion_per_set[0]+proportion_per_set[1])):]\n",
    "    if len(temp_train_set) == 0 or len(temp_validation_set) == 0 or len(temp_test_set) == 0:\n",
    "        temp_train_set = cubes_indices[:-2]\n",
    "        temp_validation_set = cubes_indices[-2:-1]\n",
    "        temp_test_set = cubes_indices[-1:]\n",
    "    train_set.extend(temp_train_set)\n",
    "    validation_set.extend(temp_validation_set)\n",
    "    test_set.extend(temp_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle the sets and save them\n",
    "np.random.shuffle(train_set)\n",
    "np.random.shuffle(validation_set)\n",
    "np.random.shuffle(test_set)\n",
    "\n",
    "# Get all the cubes infos\n",
    "train_cubes_set = data[train_set]\n",
    "validation_cubes_set = data[validation_set]\n",
    "test_cubes_set = data[test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842 229 233\n",
      "1842 229 233\n",
      "2304\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set), len(validation_set), len(test_set))\n",
    "print(len(set(train_set)), len(set(validation_set)), len(set(test_set)))\n",
    "print(len(set(train_set).union(set(validation_set).union(set(test_set)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_cubes = set(range(data.shape[0])) - set(train_set) - set(validation_set) - set(test_set)\n",
    "remaining_cubes = list(remaining_cubes)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "np.random.shuffle(remaining_cubes)\n",
    "\n",
    "train_cubes_set = np.concatenate((train_cubes_set, data[remaining_cubes[:int(len(remaining_cubes)*proportion_per_set[0])]]), axis=0)\n",
    "validation_cubes_set = np.concatenate((validation_cubes_set, data[remaining_cubes[int(len(remaining_cubes)*proportion_per_set[0]):int(len(remaining_cubes)*(proportion_per_set[0]+proportion_per_set[1]))]]), axis=0)\n",
    "test_cubes_set = np.concatenate((test_cubes_set, data[remaining_cubes[int(len(remaining_cubes)*(proportion_per_set[0]+proportion_per_set[1])):]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5002 624 628\n"
     ]
    }
   ],
   "source": [
    "print(train_cubes_set.shape[0], validation_cubes_set.shape[0], test_cubes_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5002, 25, 256, 256), (624, 25, 256, 256), (628, 25, 256, 256))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cubes_set.shape, validation_cubes_set.shape, test_cubes_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"4-sick-classes_IB_set.h5\"\n",
    "\n",
    "with h5py.File(path+\"train\"+suffix, 'w') as hf:\n",
    "    hf.create_dataset(\"cubes\", data=train_cubes_set)\n",
    "with h5py.File(path+\"validation\"+suffix, 'w') as hf:\n",
    "    hf.create_dataset(\"cubes\", data=validation_cubes_set)\n",
    "with h5py.File(path+\"test\"+suffix, 'w') as hf:\n",
    "    hf.create_dataset(\"cubes\", data=test_cubes_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
